{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "__author__ = 'Mr.数据杨'\n",
    "__explain__ = '爬虫数据存储MySQL模板'\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AERO\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py:166: Warning: (1007, \"Can't create database 'sampledb'; database exists\")\n",
      "  result = self._query(query)\n"
     ]
    }
   ],
   "source": [
    "mysql_engine = {\n",
    "    \"host\":\"localhost\", \n",
    "    \"database\":\"sampledb\", \n",
    "    \"user\":\"root\", \n",
    "    \"password\":\"admin\",\n",
    "    \"charset\":\"utf8\"}\n",
    "\n",
    "#创建数据库\n",
    "def creat_database_sampledb():\n",
    "    config_root = {\n",
    "        \"host\": \"localhost\",\n",
    "        \"user\": \"root\",\n",
    "        \"password\": \"admin\"}\n",
    "    sql = \"Create Database If Not Exists sampledb CHARSET=utf8\"\n",
    "    conn = pymysql.connect(**config_root)  # 打开数据库连接\n",
    "    try:\n",
    "        with conn.cursor() as cursor:  # 使用cursor()方法获取操作游标,并在语句结束自动关闭\n",
    "            cursor.execute(sql)  # 执行SQL\n",
    "            conn.commit()  # 提交\n",
    "    finally:\n",
    "        conn.close()\n",
    "creat_database_sampledb()\n",
    "\n",
    "def createNewsTable():\n",
    "    createTbSql = (\n",
    "        \"Create Table If Not Exists NewsTable( \"\n",
    "        \"id int primary key auto_increment, \"\n",
    "        \"title varchar(100), \"\n",
    "        \"url varchar(100), \"\n",
    "        \"date date,\"\n",
    "        \"text text)\")\n",
    "    try:\n",
    "        corsor = pymysql.connect(**mysql_engine)\n",
    "        with corsor.cursor() as cursor:\n",
    "            cursor.execute(createTbSql)\n",
    "            corsor.commit()\n",
    "    finally:\n",
    "        corsor.close()\n",
    "createNewsTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.cwestc.com/MroeNews.aspx?gd=1\"\n",
    "html = requests.get(url)\n",
    "soup = BeautifulSoup(html.text,'lxml')\n",
    "lptable = soup.find('table',width='780')\n",
    "for i in lptable.find_all(\"td\",width=\"680\"): \n",
    "    OnePage = []\n",
    "    Title = i.b.strong.a.string  # title字段\n",
    "    Url =  \"http://www.cwestc.com\"+i.find('a')['href'] # url字段\n",
    "    Date =  Url.split(\"/\")[4]  # 日期字段\n",
    "    # 根据url抓取正文\n",
    "    content = requests.get(Url)\n",
    "    content.encoding = \"utf-8\"\n",
    "    soup = BeautifulSoup(content.text,'html.parser')\n",
    "    try:\n",
    "        NewsBody = str(soup.find('td',{'class':'newsContent'}))\n",
    "    except:\n",
    "        NewsBody = \"无内容\"\n",
    "    OnePage.append((Title,Url,Date,NewsBody))\n",
    "    # 写入MySQL\n",
    "    sql = \"insert into NewsTable(id,title,url,date,text) values(Null,%s,%s,%s,%s)\"\n",
    "    conn = pymysql.connect(**mysql_engine)\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.executemany(sql, OnePage)\n",
    "            conn.commit()\n",
    "    finally:\n",
    "        conn.close()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}